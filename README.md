# LLM-s-from-Scratch
Building Large Language Models from scratch with a focus on core transformer architecture, self-attention, embeddings, tokenization, training pipelines, and inference. This repository emphasizes first-principles understanding, clean implementations, and engineering-level clarity behind modern LLM systems. Everything is going to be from scratch.....
